{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDrh9MJruyErf7/afNmnkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mushaidazenab/perceptron_iris/blob/main/perceptron_iris_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plzcykk94Ipu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Perceptron.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1YXHCuNoPY5vQVpA611BWzfn-VmiULDFF\n",
        "\"\"\"\n",
        "\n",
        "from sklearn import datasets                          # import iris dataset using datasets from sklearn\n",
        "from sklearn.model_selection import train_test_split  # splitting data into training set and testing set\n",
        "from sklearn.linear_model import Perceptron           # importing the Perceptron Algorithm from sklearn.linear_model\n",
        "from sklearn.metrics import accuracy_score            # evaluating model using accuracy metric\n",
        "\n",
        "# Link to dataset: https://archive.ics.uci.edu/ml/datasets/iris\n",
        "\n",
        "#######################################################################################\n",
        "# Step 1: Load the data and store the labels in variable x and target in variable y   #\n",
        "#######################################################################################\n",
        "\n",
        "iris_dataset = datasets.load_iris()                   # load the iris dataset\n",
        "X = iris_dataset.data[:, [2,3]]                       # load the data in indices 2 and 3 (petal length and petal width) into the variable X\n",
        "y = iris_dataset.target                               # loads the target data into variable y\n",
        "\n",
        "#######################################################################################\n",
        "# Step 2: Split the dataset into a training set and test set.                         #\n",
        "#         70% of the data should be for the training set.                             #\n",
        "#         30% of the data should be for the test set.                                 #\n",
        "#######################################################################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)   # splitting the data into training data and testing data\n",
        "\n",
        "##################################\n",
        "# Step 3: Create the model.      #\n",
        "##################################\n",
        "\n",
        "# Hyperparameters can be found on this site: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html\n",
        "perceptron_model = Perceptron(max_iter=3, tol=1e-3, eta0=0.001, fit_intercept=True, random_state=0, verbose=True)\n",
        "\n",
        "##################################\n",
        "# Step 4: Train the model.       #\n",
        "##################################\n",
        "\n",
        "perceptron_model.fit(X_train, y_train)            # train the model on training data\n",
        "\n",
        "##################################\n",
        "# Step 5: Test the model.        #\n",
        "##################################\n",
        "\n",
        "y_predict = perceptron_model.predict(X_test)      # test the model on test data\n",
        "\n",
        "##################################\n",
        "# Step 6: Evaluate the model.    #\n",
        "##################################\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_predict)  # determine accuracy\n",
        "accuracy = accuracy * 100                     # convert to percentage\n",
        "\n",
        "print(\"\\nAccuracy of model: \" + str(round(accuracy,2)) + \"%\\n\") # print accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT3LxnSQ4LEi",
        "outputId": "c64e524b-1e32-4c96-8228-592838c653c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 105, Avg. loss: 0.000164\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 210, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 315, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.003000, T: 105, Avg. loss: 0.004347\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.003000, T: 210, Avg. loss: 0.004781\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.004000, T: 315, Avg. loss: 0.003942\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 0.00, NNZs: 2, Bias: -0.008000, T: 105, Avg. loss: 0.002981\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.010000, T: 210, Avg. loss: 0.001236\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.013000, T: 315, Avg. loss: 0.002660\n",
            "Total training time: 0.00 seconds.\n",
            "\n",
            "Accuracy of model: 40.0%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "\n",
        "from sklearn import datasets #gives ready to use data sets like iris being used here\n",
        "from sklearn.model_selection import train_test_split #dividing data into training and testing\n",
        "from sklearn.linear_model import Perceptron #train\n",
        "from sklearn.metrics import accuracy_score #evaluate/test\n",
        "\n",
        "\n",
        "\n",
        "#load iris data required\n",
        "\n",
        "iris_dataset = datasets.load_iris() #loads iris dataset\n",
        "x = iris_dataset.data[:,[2,3]]\n",
        "y = iris_dataset.target #type of flower\n",
        "\n",
        "\n",
        "#split the data set\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#create a perceptron model\n",
        "\n",
        "perceptron_model = Perceptron(max_iter=3, tol=1e-3, eta0=0.001, fit_intercept=True, random_state=0, verbose = True)\n",
        "\n",
        "\n",
        "#train\n",
        "perceptron_model.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "y_predict = perceptron_model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_predict)\n",
        "accuracy = accuracy*100\n",
        "print(\"\\n accuracy of model: \" + str(round(accuracy,2)) + \"%\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdP1ot_j4Q36",
        "outputId": "aee30b16-547c-42fb-ceb1-e60994e45518"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 105, Avg. loss: 0.000154\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 210, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.00, NNZs: 2, Bias: 0.002000, T: 315, Avg. loss: 0.000000\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 0.00, NNZs: 2, Bias: -0.005000, T: 105, Avg. loss: 0.004222\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.00, NNZs: 2, Bias: -0.006000, T: 210, Avg. loss: 0.004210\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.003000, T: 315, Avg. loss: 0.005759\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 1\n",
            "Norm: 0.00, NNZs: 2, Bias: -0.006000, T: 105, Avg. loss: 0.001588\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.009000, T: 210, Avg. loss: 0.001921\n",
            "Total training time: 0.00 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.01, NNZs: 2, Bias: -0.013000, T: 315, Avg. loss: 0.002442\n",
            "Total training time: 0.00 seconds.\n",
            "\n",
            " accuracy of model: 44.44%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZao1Jsv9Vu-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}